{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save JSON Cache File\n",
    "\n",
    "This notebook processes the JSON files into index tokens and document vectors and save to cache files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from cord import ResearchPapers\n",
    "import pandas as pd\n",
    "from cord.core import split_df, DOCUMENT_VECTOR_PATH\n",
    "from cord.jsonpaper import load_json_texts, list_json_files_in, load_json_cache\n",
    "from cord.core import JSON_CATALOGS, BIORXIV_MEDRXIV, CUSTOM_LICENSE, \\\n",
    "    COMM_USE_SUBSET, NONCOMM_USE_SUBSET, find_data_dir, cord_support_dir\n",
    "from cord.text import SIMPLE_STOPWORDS\n",
    "from pathlib import Path, PurePath\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 1200\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Load Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#document_vectors = pd.read_parquet(DOCUMENT_VECTOR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Index Tokens and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "import pickle\n",
    "\n",
    "def save_dictionary(dictionary, save_path):\n",
    "    print('Saving dictionary to', save_path)\n",
    "    with save_path.open('wb') as f:\n",
    "        dictionary.save(f)\n",
    "        \n",
    "def token_2ints(json_text_df):\n",
    "    dictionary = Dictionary(json_text_df.index_tokens)\n",
    "    json_text_df['token_int'] \\\n",
    "            = json_text_df.index_tokens.apply(lambda tokens:  [dictionary.token2id[t] for t in tokens])\n",
    "    return dictionary, json_text_df.drop(columns=['index_tokens'])\n",
    "\n",
    "\n",
    "def save_json_cache_files():\n",
    "    json_cache_path = Path(find_data_dir()).parent / 'json-cache'\n",
    "    if json_cache_path.exists():\n",
    "        print('Json Cache dir exists')\n",
    "        for cache_file in json_cache_path.glob('*.pq'):\n",
    "            print('Removing', cache_file)\n",
    "            cache_file.unlink()\n",
    "    else:\n",
    "        print('Creating directory', json_cache_path)\n",
    "        json_cache_path.mkdir(exist_ok=True)\n",
    "\n",
    "    max_df_size = 2000\n",
    "    for catalog in JSON_CATALOGS:\n",
    "        json_text_df = load_json_texts(catalog, tokenize=True)\n",
    "        dictionary, json_text_df = token_2ints(json_text_df)\n",
    "        # Don't use the authors column\n",
    "        json_text_df = json_text_df\n",
    "        save_dictionary(dictionary, json_cache_path / f'jsoncache_{catalog}.dict' )\n",
    "        #if catalog in [BIORXIV_MEDRXIV, NONCOMM_USE_SUBSET]:\n",
    "        catalog_save_path = json_cache_path / f'jsoncache_{catalog}.pq'\n",
    "        print('Saving to', catalog_save_path)\n",
    "        json_text_df.to_parquet(catalog_save_path)\n",
    "    \"\"\"\n",
    "\n",
    "        else:\n",
    "            print('Splitting files for', catalog)\n",
    "            json_text_parts = split_df(json_text_df, max_df_size)\n",
    "            for i in range(0, len(json_text_parts)):\n",
    "                df = json_text_parts[i]\n",
    "                catalog_save_path = json_cache_path / f'jsoncache_{catalog}_{i}.pq'\n",
    "                print('Saving to', catalog_save_path)\n",
    "                df.to_parquet(catalog_save_path)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Json Cache dir exists\n",
      "Removing ..\\data\\json-cache\\jsoncache_biorxiv_medrxiv.pq\n",
      "Removing ..\\data\\json-cache\\jsoncache_comm_use_subset.pq\n",
      "Removing ..\\data\\json-cache\\jsoncache_custom_license.pq\n",
      "Removing ..\\data\\json-cache\\jsoncache_noncomm_use_subset.pq\n",
      "Loading json from comm_use_subset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8dde9718ee424db7402ff6362f3907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18672.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dictionary to ..\\data\\json-cache\\jsoncache_comm_use_subset.dict\n",
      "Saving to ..\\data\\json-cache\\jsoncache_comm_use_subset.pq\n",
      "Loading json from biorxiv_medrxiv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e80bb2fe0dc43e88d68df935577c509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dictionary to ..\\data\\json-cache\\jsoncache_biorxiv_medrxiv.dict\n",
      "Saving to ..\\data\\json-cache\\jsoncache_biorxiv_medrxiv.pq\n",
      "Loading json from noncomm_use_subset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1314450eef484c11ae86aae75bd85873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dictionary to ..\\data\\json-cache\\jsoncache_noncomm_use_subset.dict\n",
      "Saving to ..\\data\\json-cache\\jsoncache_noncomm_use_subset.pq\n",
      "Loading json from custom_license\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480ebc9a5b8442eea887e76b1e460e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dictionary to ..\\data\\json-cache\\jsoncache_custom_license.dict\n",
      "Saving to ..\\data\\json-cache\\jsoncache_custom_license.pq\n"
     ]
    }
   ],
   "source": [
    "save_json_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from ..\\data\\CORD-19-research-challenge\n",
      "Cleaning metadata\n",
      "Applying tags to metadata\n",
      "\n",
      "Indexing research papers\n",
      "Creating the BM25 index from the text contents of the papers\n",
      "Loading json cache files for comm_use_subset\n",
      "Loaded comm_use_subset json cache in 42 seconds\n",
      "Json document tokens loaded from cache\n",
      "Loading json cache files for biorxiv_medrxiv\n",
      "Loaded biorxiv_medrxiv json cache in 2 seconds\n",
      "Json document tokens loaded from cache\n",
      "Loading json cache files for noncomm_use_subset\n",
      "Loaded noncomm_use_subset json cache in 9 seconds\n",
      "Json document tokens loaded from cache\n",
      "Loading json cache files for custom_license\n",
      "Loaded custom_license json cache in 76 seconds\n",
      "Json document tokens loaded from cache\n",
      "There are 13056 papers that will be indexed using the abstract instead of the contents\n",
      "Finished indexing in 142 seconds\n"
     ]
    }
   ],
   "source": [
    "#papers = ResearchPapers.load(index='text')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cord",
   "language": "python",
   "name": "cord"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
